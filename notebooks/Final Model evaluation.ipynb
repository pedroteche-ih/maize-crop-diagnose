{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "chdir: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdotenv\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      5\u001b[0m load_dotenv(dotenv_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlocal_paths.env\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m os\u001b[39m.\u001b[39;49mchdir(os\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mLOCAL_REPO_DIR\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      8\u001b[0m K \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mbackend\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscheduler\u001b[39;00m \u001b[39mimport\u001b[39;00m OneCycleSchedulerNoMom\n",
      "\u001b[0;31mTypeError\u001b[0m: chdir: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os, optuna\n",
    "from tensorflow import keras\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"local_paths.env\")\n",
    "\n",
    "os.chdir(os.getenv(\"LOCAL_REPO_DIR\"))\n",
    "K = keras.backend\n",
    "from src.models.scheduler import OneCycleSchedulerNoMom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 64 * 2\n",
    "IMG_WIDTH = 48 * 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 50\n",
    "DATA_DIR = os.getenv(\"LOCAL_DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15349 files belonging to 3 classes.\n",
      "Using 10745 files for training.\n",
      "Using 4604 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.3,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "class_names = train_set.class_names\n",
    "num_classes = len(train_set.class_names)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_set = train_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "test_set = val_set.shuffle(buffer_size=512).take(2000//BATCH_SIZE)\n",
    "val_set = val_set.skip(2000//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 10745\n",
    "TEST_SIZE = BATCH_SIZE * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_study = optuna.load_study(\n",
    "    study_name=\"resnet_onecycle_drop_sgd\",\n",
    "    storage=\"sqlite:///models/db_maize_models.sqlite3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "336/336 - 53s - loss: 0.3442 - accuracy: 0.8632 - val_loss: 1.6470 - val_accuracy: 0.6369 - 53s/epoch - 159ms/step\n",
      "Epoch 2/50\n",
      "336/336 - 46s - loss: 0.2346 - accuracy: 0.9160 - val_loss: 0.4919 - val_accuracy: 0.7863 - 46s/epoch - 136ms/step\n",
      "Epoch 3/50\n",
      "336/336 - 45s - loss: 0.1951 - accuracy: 0.9321 - val_loss: 0.3798 - val_accuracy: 0.8478 - 45s/epoch - 134ms/step\n",
      "Epoch 4/50\n",
      "336/336 - 45s - loss: 0.1715 - accuracy: 0.9409 - val_loss: 1.1461 - val_accuracy: 0.7288 - 45s/epoch - 133ms/step\n",
      "Epoch 5/50\n",
      "336/336 - 45s - loss: 0.1491 - accuracy: 0.9480 - val_loss: 1.8696 - val_accuracy: 0.6621 - 45s/epoch - 134ms/step\n",
      "Epoch 6/50\n",
      "336/336 - 45s - loss: 0.1309 - accuracy: 0.9551 - val_loss: 1.9993 - val_accuracy: 0.6606 - 45s/epoch - 133ms/step\n",
      "Epoch 7/50\n",
      "336/336 - 45s - loss: 0.1163 - accuracy: 0.9603 - val_loss: 2.3317 - val_accuracy: 0.6470 - 45s/epoch - 134ms/step\n",
      "Epoch 8/50\n",
      "336/336 - 45s - loss: 0.1074 - accuracy: 0.9627 - val_loss: 2.0528 - val_accuracy: 0.6925 - 45s/epoch - 135ms/step\n",
      "Epoch 9/50\n",
      "336/336 - 45s - loss: 0.0965 - accuracy: 0.9671 - val_loss: 1.6612 - val_accuracy: 0.7520 - 45s/epoch - 134ms/step\n",
      "Epoch 10/50\n",
      "336/336 - 45s - loss: 0.0886 - accuracy: 0.9692 - val_loss: 1.0918 - val_accuracy: 0.7908 - 45s/epoch - 134ms/step\n",
      "Epoch 11/50\n",
      "336/336 - 45s - loss: 0.0815 - accuracy: 0.9730 - val_loss: 0.8928 - val_accuracy: 0.8207 - 45s/epoch - 134ms/step\n",
      "Epoch 12/50\n",
      "336/336 - 45s - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.5794 - val_accuracy: 0.8553 - 45s/epoch - 134ms/step\n",
      "Epoch 13/50\n",
      "336/336 - 45s - loss: 0.0702 - accuracy: 0.9752 - val_loss: 0.3208 - val_accuracy: 0.9057 - 45s/epoch - 134ms/step\n",
      "Epoch 14/50\n",
      "336/336 - 45s - loss: 0.0686 - accuracy: 0.9761 - val_loss: 0.3705 - val_accuracy: 0.8891 - 45s/epoch - 134ms/step\n",
      "Epoch 15/50\n",
      "336/336 - 45s - loss: 0.0589 - accuracy: 0.9808 - val_loss: 0.4077 - val_accuracy: 0.8942 - 45s/epoch - 134ms/step\n",
      "Epoch 16/50\n",
      "336/336 - 45s - loss: 0.0554 - accuracy: 0.9820 - val_loss: 0.1748 - val_accuracy: 0.9455 - 45s/epoch - 135ms/step\n",
      "Epoch 17/50\n",
      "336/336 - 45s - loss: 0.0543 - accuracy: 0.9825 - val_loss: 0.3391 - val_accuracy: 0.9083 - 45s/epoch - 134ms/step\n",
      "Epoch 18/50\n",
      "336/336 - 45s - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.1820 - val_accuracy: 0.9419 - 45s/epoch - 134ms/step\n",
      "Epoch 19/50\n",
      "336/336 - 45s - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.3115 - val_accuracy: 0.9108 - 45s/epoch - 134ms/step\n",
      "Epoch 20/50\n",
      "336/336 - 45s - loss: 0.0491 - accuracy: 0.9842 - val_loss: 0.3565 - val_accuracy: 0.8942 - 45s/epoch - 134ms/step\n",
      "Epoch 21/50\n",
      "336/336 - 45s - loss: 0.0408 - accuracy: 0.9868 - val_loss: 0.8349 - val_accuracy: 0.8222 - 45s/epoch - 134ms/step\n",
      "Epoch 22/50\n",
      "336/336 - 46s - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.5814 - val_accuracy: 0.8760 - 46s/epoch - 135ms/step\n",
      "Epoch 23/50\n",
      "336/336 - 44s - loss: 0.0383 - accuracy: 0.9889 - val_loss: 0.2715 - val_accuracy: 0.9380 - 44s/epoch - 132ms/step\n",
      "Epoch 24/50\n",
      "336/336 - 45s - loss: 0.0377 - accuracy: 0.9879 - val_loss: 0.5521 - val_accuracy: 0.8596 - 45s/epoch - 135ms/step\n",
      "Epoch 25/50\n",
      "336/336 - 45s - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.4841 - val_accuracy: 0.8810 - 45s/epoch - 135ms/step\n",
      "Epoch 26/50\n",
      "336/336 - 45s - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.2288 - val_accuracy: 0.9476 - 45s/epoch - 135ms/step\n",
      "Epoch 27/50\n",
      "336/336 - 45s - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.1180 - val_accuracy: 0.9636 - 45s/epoch - 135ms/step\n",
      "Epoch 28/50\n",
      "336/336 - 45s - loss: 0.0121 - accuracy: 0.9975 - val_loss: 0.4399 - val_accuracy: 0.9030 - 45s/epoch - 135ms/step\n",
      "Epoch 29/50\n",
      "336/336 - 45s - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.1294 - val_accuracy: 0.9667 - 45s/epoch - 135ms/step\n",
      "Epoch 30/50\n",
      "336/336 - 45s - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.1704 - val_accuracy: 0.9561 - 45s/epoch - 135ms/step\n",
      "Epoch 31/50\n",
      "336/336 - 46s - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.1065 - val_accuracy: 0.9753 - 46s/epoch - 136ms/step\n",
      "Epoch 32/50\n",
      "336/336 - 47s - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1004 - val_accuracy: 0.9803 - 47s/epoch - 139ms/step\n",
      "Epoch 33/50\n",
      "336/336 - 46s - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0763 - val_accuracy: 0.9808 - 46s/epoch - 136ms/step\n",
      "Epoch 34/50\n",
      "336/336 - 46s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0910 - val_accuracy: 0.9753 - 46s/epoch - 138ms/step\n",
      "Epoch 35/50\n",
      "336/336 - 45s - loss: 9.6921e-04 - accuracy: 0.9999 - val_loss: 0.0751 - val_accuracy: 0.9814 - 45s/epoch - 135ms/step\n",
      "Epoch 36/50\n",
      "336/336 - 45s - loss: 5.3339e-04 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9818 - 45s/epoch - 135ms/step\n",
      "Epoch 37/50\n",
      "336/336 - 46s - loss: 4.2033e-04 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9824 - 46s/epoch - 136ms/step\n",
      "Epoch 38/50\n",
      "336/336 - 45s - loss: 3.5888e-04 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9813 - 45s/epoch - 135ms/step\n",
      "Epoch 39/50\n",
      "336/336 - 45s - loss: 3.1871e-04 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9768 - 45s/epoch - 134ms/step\n",
      "Epoch 40/50\n",
      "336/336 - 45s - loss: 2.8975e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9768 - 45s/epoch - 135ms/step\n",
      "Epoch 41/50\n",
      "336/336 - 46s - loss: 2.6803e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9808 - 46s/epoch - 137ms/step\n",
      "Epoch 42/50\n",
      "336/336 - 45s - loss: 2.5129e-04 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9819 - 45s/epoch - 135ms/step\n",
      "Epoch 43/50\n",
      "336/336 - 45s - loss: 2.3819e-04 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9788 - 45s/epoch - 135ms/step\n",
      "Epoch 44/50\n",
      "336/336 - 45s - loss: 2.2788e-04 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9783 - 45s/epoch - 135ms/step\n",
      "Epoch 45/50\n",
      "336/336 - 45s - loss: 2.1980e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9793 - 45s/epoch - 135ms/step\n",
      "Epoch 46/50\n",
      "336/336 - 45s - loss: 2.1359e-04 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9758 - 45s/epoch - 135ms/step\n",
      "Epoch 47/50\n",
      "336/336 - 45s - loss: 2.0891e-04 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9778 - 45s/epoch - 135ms/step\n"
     ]
    }
   ],
   "source": [
    "# Architecture Hyperparameters\n",
    "size_dense = loaded_study.best_params[\"size_dense\"]\n",
    "activation_function = loaded_study.best_params[\"activation_function\"]\n",
    "dropout_rate = loaded_study.best_params[\"dropout_rate\"]\n",
    "# Input layers\n",
    "input = keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "rescale = keras.layers.Rescaling(1.0 / 255)(input)\n",
    "conv_in = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(7, 7), strides=(2, 2), activation=activation_function\n",
    ")(rescale)\n",
    "pool_in = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(\n",
    "    conv_in\n",
    ")\n",
    "# R1\n",
    "conv_r1_1 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(pool_in)\n",
    "bn_r1_1 = keras.layers.BatchNormalization()(conv_r1_1)\n",
    "if activation_function == \"relu\":\n",
    "    relu_r1_1 = keras.layers.ReLU()(bn_r1_1)\n",
    "else:\n",
    "    relu_r1_1 = keras.layers.ELU()(bn_r1_1)\n",
    "conv_r1_2 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(relu_r1_1)\n",
    "bn_r1_2 = keras.layers.BatchNormalization()(conv_r1_2)\n",
    "skip_r1 = keras.layers.Add()([bn_r1_2, pool_in])\n",
    "if activation_function == \"relu\":\n",
    "    relu_r1_2 = keras.layers.ReLU()(skip_r1)\n",
    "else:\n",
    "    relu_r1_2 = keras.layers.ELU()(skip_r1)\n",
    "# R2\n",
    "conv_r2_1 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(relu_r1_2)\n",
    "bn_r2_1 = keras.layers.BatchNormalization()(conv_r2_1)\n",
    "if activation_function == \"relu\":\n",
    "    relu_r2_1 = keras.layers.ReLU()(bn_r2_1)\n",
    "else:\n",
    "    relu_r2_1 = keras.layers.ELU()(bn_r2_1)\n",
    "conv_r2_2 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(relu_r2_1)\n",
    "bn_r2_2 = keras.layers.BatchNormalization()(conv_r2_2)\n",
    "skip_r2 = keras.layers.Add()([bn_r2_2, relu_r1_2])\n",
    "if activation_function == \"relu\":\n",
    "    relu_r2_2 = keras.layers.ReLU()(skip_r2)\n",
    "else:\n",
    "    relu_r2_2 = keras.layers.ELU()(skip_r2)\n",
    "# R3\n",
    "conv_r3_skip = keras.layers.Conv2D(128, 1, 2, padding=\"same\")(relu_r2_2)\n",
    "conv_r3_1 = keras.layers.Conv2D(128, 3, 2, padding=\"same\")(relu_r2_2)\n",
    "bn_r3_1 = keras.layers.BatchNormalization()(conv_r3_1)\n",
    "if activation_function == \"relu\":\n",
    "    relu_r3_1 = keras.layers.ReLU()(bn_r3_1)\n",
    "else:\n",
    "    relu_r3_1 = keras.layers.ELU()(bn_r3_1)\n",
    "conv_r3_2 = keras.layers.Conv2D(128, 3, 1, padding=\"same\")(relu_r3_1)\n",
    "bn_r3_2 = keras.layers.BatchNormalization()(conv_r3_2)\n",
    "skip_r3 = keras.layers.Add()([bn_r3_2, conv_r3_skip])\n",
    "if activation_function == \"relu\":\n",
    "    relu_r3_2 = keras.layers.ReLU()(skip_r3)\n",
    "else:\n",
    "    relu_r3_2 = keras.layers.ELU()(skip_r3)\n",
    "# Output layers\n",
    "pool_out = keras.layers.GlobalAveragePooling2D()(relu_r3_2)\n",
    "dense_out = keras.layers.Dense(size_dense, activation=activation_function)(pool_out)\n",
    "dropout = keras.layers.Dropout(dropout_rate)\n",
    "output = keras.layers.Dense(num_classes, activation=\"softmax\")(dense_out)\n",
    "# Model\n",
    "model = keras.Model(inputs=input, outputs=output)\n",
    "# Fitting model\n",
    "\n",
    "max_lr = loaded_study.best_params[\"max_lr\"]\n",
    "start_lr_prop = loaded_study.best_params[\"start_lr_prop\"]\n",
    "last_lr = loaded_study.best_params[\"last_lr\"]\n",
    "onecycle = OneCycleSchedulerNoMom(\n",
    "    TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "    max_lr=max_lr,\n",
    "    start_lr=start_lr_prop * max_lr,\n",
    "    last_lr=last_lr,\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=20,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "h = model.fit(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, onecycle],\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 6s 54ms/step\n",
      "F1 score: 0.98, Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "y_val = np.concatenate([y for x, y in val_set])\n",
    "y_val_pred = np.argmax(model.predict(val_set), axis=1)\n",
    "f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"F1 score: {np.round(f1, 2)}, Accuracy: {np.round(acc, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/maize_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
