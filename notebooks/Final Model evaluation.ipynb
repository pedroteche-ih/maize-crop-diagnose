{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, optuna\n",
    "from tensorflow import keras\n",
    "\n",
    "os.chdir(\"/Users/pedroteche/Documents/GitHub/maize-crop-diagnose/\")\n",
    "K = keras.backend\n",
    "from src.models.scheduler import OneCycleSchedulerNoMom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 64 * 2\n",
    "IMG_WIDTH = 48 * 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 50\n",
    "TRAIN_DATA_DIR = \"/Volumes/DOCK-HD/Data/maize-crop-diagnose/train\"\n",
    "TEST_DATA_DIR = \"/Volumes/DOCK-HD/Data/maize-crop-diagnose/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14749 files belonging to 3 classes.\n",
      "Using 11800 files for training.\n",
      "Using 2949 files for validation.\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "class_names = train_set.class_names\n",
    "num_classes = len(train_set.class_names)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_set = train_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "val_set = val_set.prefetch(buffer_size=AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 11800\n",
    "TEST_SIZE = 2949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DATA_DIR,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_study = optuna.load_study(\n",
    "    study_name=\"resnet_onecycle_drop_sgd\",\n",
    "    storage=\"sqlite:///models/db_maize_models.sqlite3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 - 49s - loss: 0.2599 - accuracy: 0.9003 - val_loss: 1.0676 - val_accuracy: 0.7369 - 49s/epoch - 133ms/step\n",
      "Epoch 3/50\n",
      "369/369 - 46s - loss: 0.2138 - accuracy: 0.9188 - val_loss: 1.3075 - val_accuracy: 0.7270 - 46s/epoch - 125ms/step\n",
      "Epoch 4/50\n",
      "369/369 - 46s - loss: 0.1872 - accuracy: 0.9289 - val_loss: 1.1195 - val_accuracy: 0.7409 - 46s/epoch - 124ms/step\n",
      "Epoch 5/50\n",
      "369/369 - 50s - loss: 0.1669 - accuracy: 0.9377 - val_loss: 0.8006 - val_accuracy: 0.7789 - 50s/epoch - 135ms/step\n",
      "Epoch 6/50\n",
      "369/369 - 50s - loss: 0.1490 - accuracy: 0.9449 - val_loss: 0.6081 - val_accuracy: 0.8094 - 50s/epoch - 134ms/step\n",
      "Epoch 7/50\n",
      "369/369 - 47s - loss: 0.1340 - accuracy: 0.9508 - val_loss: 0.4676 - val_accuracy: 0.8308 - 47s/epoch - 128ms/step\n",
      "Epoch 8/50\n",
      "369/369 - 47s - loss: 0.1214 - accuracy: 0.9559 - val_loss: 0.3195 - val_accuracy: 0.8715 - 47s/epoch - 129ms/step\n",
      "Epoch 9/50\n",
      "369/369 - 46s - loss: 0.1128 - accuracy: 0.9597 - val_loss: 0.2139 - val_accuracy: 0.9088 - 46s/epoch - 124ms/step\n",
      "Epoch 10/50\n",
      "369/369 - 46s - loss: 0.1032 - accuracy: 0.9619 - val_loss: 0.1556 - val_accuracy: 0.9403 - 46s/epoch - 124ms/step\n",
      "Epoch 11/50\n",
      "369/369 - 46s - loss: 0.0959 - accuracy: 0.9657 - val_loss: 0.1677 - val_accuracy: 0.9366 - 46s/epoch - 124ms/step\n",
      "Epoch 12/50\n",
      "369/369 - 47s - loss: 0.0892 - accuracy: 0.9677 - val_loss: 0.1758 - val_accuracy: 0.9444 - 47s/epoch - 127ms/step\n",
      "Epoch 13/50\n",
      "369/369 - 49s - loss: 0.0843 - accuracy: 0.9696 - val_loss: 0.2863 - val_accuracy: 0.9108 - 49s/epoch - 132ms/step\n",
      "Epoch 14/50\n",
      "369/369 - 48s - loss: 0.0786 - accuracy: 0.9722 - val_loss: 0.2282 - val_accuracy: 0.9264 - 48s/epoch - 130ms/step\n",
      "Epoch 15/50\n",
      "369/369 - 49s - loss: 0.0728 - accuracy: 0.9750 - val_loss: 0.4884 - val_accuracy: 0.8834 - 49s/epoch - 132ms/step\n",
      "Epoch 16/50\n",
      "369/369 - 48s - loss: 0.0696 - accuracy: 0.9772 - val_loss: 0.3577 - val_accuracy: 0.8908 - 48s/epoch - 130ms/step\n",
      "Epoch 17/50\n",
      "369/369 - 48s - loss: 0.0659 - accuracy: 0.9784 - val_loss: 0.4500 - val_accuracy: 0.8803 - 48s/epoch - 130ms/step\n",
      "Epoch 18/50\n",
      "369/369 - 48s - loss: 0.0624 - accuracy: 0.9785 - val_loss: 0.3372 - val_accuracy: 0.8983 - 48s/epoch - 130ms/step\n",
      "Epoch 19/50\n",
      "369/369 - 47s - loss: 0.0629 - accuracy: 0.9791 - val_loss: 0.3245 - val_accuracy: 0.9095 - 47s/epoch - 127ms/step\n",
      "Epoch 20/50\n",
      "369/369 - 46s - loss: 0.0588 - accuracy: 0.9799 - val_loss: 0.4476 - val_accuracy: 0.8891 - 46s/epoch - 124ms/step\n",
      "Epoch 21/50\n",
      "369/369 - 46s - loss: 0.0509 - accuracy: 0.9842 - val_loss: 0.8836 - val_accuracy: 0.8613 - 46s/epoch - 125ms/step\n",
      "Epoch 22/50\n",
      "369/369 - 48s - loss: 0.1154 - accuracy: 0.9672 - val_loss: 0.1591 - val_accuracy: 0.9478 - 48s/epoch - 130ms/step\n",
      "Epoch 23/50\n",
      "369/369 - 49s - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.8175 - val_accuracy: 0.8260 - 49s/epoch - 132ms/step\n",
      "Epoch 24/50\n",
      "369/369 - 49s - loss: 0.0403 - accuracy: 0.9870 - val_loss: 2.4073 - val_accuracy: 0.5765 - 49s/epoch - 132ms/step\n",
      "Epoch 25/50\n",
      "369/369 - 48s - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.8873 - val_accuracy: 0.7440 - 48s/epoch - 130ms/step\n",
      "Epoch 26/50\n",
      "369/369 - 48s - loss: 0.0314 - accuracy: 0.9907 - val_loss: 0.1449 - val_accuracy: 0.9542 - 48s/epoch - 130ms/step\n",
      "Epoch 27/50\n",
      "369/369 - 47s - loss: 0.0648 - accuracy: 0.9807 - val_loss: 0.1044 - val_accuracy: 0.9624 - 47s/epoch - 128ms/step\n",
      "Epoch 28/50\n",
      "369/369 - 46s - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.2338 - val_accuracy: 0.9308 - 46s/epoch - 124ms/step\n",
      "Epoch 29/50\n",
      "369/369 - 49s - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.0880 - val_accuracy: 0.9698 - 49s/epoch - 132ms/step\n",
      "Epoch 30/50\n",
      "369/369 - 48s - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.0916 - val_accuracy: 0.9719 - 48s/epoch - 130ms/step\n",
      "Epoch 31/50\n",
      "369/369 - 47s - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.1314 - val_accuracy: 0.9600 - 47s/epoch - 129ms/step\n",
      "Epoch 32/50\n",
      "369/369 - 49s - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.1293 - val_accuracy: 0.9586 - 49s/epoch - 133ms/step\n",
      "Epoch 33/50\n",
      "369/369 - 48s - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.1724 - val_accuracy: 0.9444 - 48s/epoch - 130ms/step\n",
      "Epoch 34/50\n",
      "369/369 - 48s - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.1769 - val_accuracy: 0.9454 - 48s/epoch - 129ms/step\n",
      "Epoch 35/50\n",
      "369/369 - 47s - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.1858 - val_accuracy: 0.9481 - 47s/epoch - 127ms/step\n",
      "Epoch 36/50\n",
      "369/369 - 47s - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.5257 - val_accuracy: 0.8464 - 47s/epoch - 126ms/step\n",
      "Epoch 37/50\n",
      "369/369 - 48s - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.3533 - val_accuracy: 0.9030 - 48s/epoch - 130ms/step\n",
      "Epoch 38/50\n",
      "369/369 - 47s - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.3149 - val_accuracy: 0.9173 - 47s/epoch - 126ms/step\n",
      "Epoch 39/50\n",
      "369/369 - 47s - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.2711 - val_accuracy: 0.9322 - 47s/epoch - 127ms/step\n",
      "Epoch 40/50\n",
      "369/369 - 47s - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.2194 - val_accuracy: 0.9417 - 47s/epoch - 127ms/step\n"
     ]
    }
   ],
   "source": [
    "# Architecture Hyperparameters\n",
    "size_dense = loaded_study.best_params[\"size_dense\"]\n",
    "activation_function = loaded_study.best_params[\"activation_function\"]\n",
    "dropout_rate = loaded_study.best_params[\"dropout_rate\"]\n",
    "# Input layers\n",
    "input = keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "rescale = keras.layers.Rescaling(1.0 / 255)(input)\n",
    "conv_in = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(7, 7), strides=(2, 2), activation=activation_function\n",
    ")(rescale)\n",
    "pool_in = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(\n",
    "    conv_in\n",
    ")\n",
    "# R1\n",
    "conv_r1_1 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(pool_in)\n",
    "bn_r1_1 = keras.layers.BatchNormalization()(conv_r1_1)\n",
    "if activation_function == \"relu\":\n",
    "    relu_r1_1 = keras.layers.ReLU()(bn_r1_1)\n",
    "else:\n",
    "    relu_r1_1 = keras.layers.ELU()(bn_r1_1)\n",
    "conv_r1_2 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(relu_r1_1)\n",
    "bn_r1_2 = keras.layers.BatchNormalization()(conv_r1_2)\n",
    "skip_r1 = keras.layers.Add()([bn_r1_2, pool_in])\n",
    "if activation_function == \"relu\":\n",
    "    relu_r1_2 = keras.layers.ReLU()(skip_r1)\n",
    "else:\n",
    "    relu_r1_2 = keras.layers.ELU()(skip_r1)\n",
    "# R2\n",
    "conv_r2_1 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(relu_r1_2)\n",
    "bn_r2_1 = keras.layers.BatchNormalization()(conv_r2_1)\n",
    "if activation_function == \"relu\":\n",
    "    relu_r2_1 = keras.layers.ReLU()(bn_r2_1)\n",
    "else:\n",
    "    relu_r2_1 = keras.layers.ELU()(bn_r2_1)\n",
    "conv_r2_2 = keras.layers.Conv2D(64, 3, 1, padding=\"same\")(relu_r2_1)\n",
    "bn_r2_2 = keras.layers.BatchNormalization()(conv_r2_2)\n",
    "skip_r2 = keras.layers.Add()([bn_r2_2, relu_r1_2])\n",
    "if activation_function == \"relu\":\n",
    "    relu_r2_2 = keras.layers.ReLU()(skip_r2)\n",
    "else:\n",
    "    relu_r2_2 = keras.layers.ELU()(skip_r2)\n",
    "# R3\n",
    "conv_r3_skip = keras.layers.Conv2D(128, 1, 2, padding=\"same\")(relu_r2_2)\n",
    "conv_r3_1 = keras.layers.Conv2D(128, 3, 2, padding=\"same\")(relu_r2_2)\n",
    "bn_r3_1 = keras.layers.BatchNormalization()(conv_r3_1)\n",
    "if activation_function == \"relu\":\n",
    "    relu_r3_1 = keras.layers.ReLU()(bn_r3_1)\n",
    "else:\n",
    "    relu_r3_1 = keras.layers.ELU()(bn_r3_1)\n",
    "conv_r3_2 = keras.layers.Conv2D(128, 3, 1, padding=\"same\")(relu_r3_1)\n",
    "bn_r3_2 = keras.layers.BatchNormalization()(conv_r3_2)\n",
    "skip_r3 = keras.layers.Add()([bn_r3_2, conv_r3_skip])\n",
    "if activation_function == \"relu\":\n",
    "    relu_r3_2 = keras.layers.ReLU()(skip_r3)\n",
    "else:\n",
    "    relu_r3_2 = keras.layers.ELU()(skip_r3)\n",
    "# Output layers\n",
    "pool_out = keras.layers.GlobalAveragePooling2D()(relu_r3_2)\n",
    "dense_out = keras.layers.Dense(size_dense, activation=activation_function)(pool_out)\n",
    "dropout = keras.layers.Dropout(dropout_rate)\n",
    "output = keras.layers.Dense(num_classes, activation=\"softmax\")(dense_out)\n",
    "# Model\n",
    "model = keras.Model(inputs=input, outputs=output)\n",
    "# Fitting model\n",
    "\n",
    "max_lr = loaded_study.best_params[\"max_lr\"]\n",
    "start_lr_prop = loaded_study.best_params[\"start_lr_prop\"]\n",
    "last_lr = loaded_study.best_params[\"last_lr\"]\n",
    "onecycle = OneCycleSchedulerNoMom(\n",
    "    TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "    max_lr=max_lr,\n",
    "    start_lr=start_lr_prop * max_lr,\n",
    "    last_lr=last_lr,\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=20,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "h = model.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, onecycle],\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 96, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 128, 96, 3)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 61, 45, 64)   9472        ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 31, 23, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 31, 23, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 31, 23, 64)  256         ['conv2d_1[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " elu (ELU)                      (None, 31, 23, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 31, 23, 64)   36928       ['elu[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 31, 23, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 31, 23, 64)   0           ['batch_normalization_1[0][0]',  \n",
      "                                                                  'max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " elu_1 (ELU)                    (None, 31, 23, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 31, 23, 64)   36928       ['elu_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 31, 23, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " elu_2 (ELU)                    (None, 31, 23, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 31, 23, 64)   36928       ['elu_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 31, 23, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 31, 23, 64)   0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'elu_1[0][0]']                  \n",
      "                                                                                                  \n",
      " elu_3 (ELU)                    (None, 31, 23, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 12, 128)  73856       ['elu_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 12, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " elu_4 (ELU)                    (None, 16, 12, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 12, 128)  147584      ['elu_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 12, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 12, 128)  8320        ['elu_3[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 12, 128)  0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " elu_5 (ELU)                    (None, 16, 12, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['elu_5[0][0]']                  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          33024       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            771         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 422,787\n",
      "Trainable params: 421,763\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.2576820e-09, 9.9062192e-01, 9.3781501e-03],\n",
       "       [3.0145220e-11, 1.3470421e-14, 1.0000000e+00],\n",
       "       [1.1704127e-10, 9.9999952e-01, 4.7776570e-07],\n",
       "       ...,\n",
       "       [2.8578151e-02, 9.6941459e-01, 2.0072246e-03],\n",
       "       [9.9986720e-01, 8.7887986e-07, 1.3199604e-04],\n",
       "       [9.8347677e-11, 9.9061710e-01, 9.3829092e-03]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.concatenate([y for x, y in val_set])\n",
    "y_val_pred = np.argmax(model.predict(val_set), axis=1)\n",
    "f1_score(y_val, y_val_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 52ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33146916668191717"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.concatenate([y for x, y in test_set])\n",
    "y_test_pred = np.argmax(model.predict(test_set), axis=1)\n",
    "f1_score(y_test, y_test_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694269997840284"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
