{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os, optuna\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "K = keras.backend\n",
    "# Changing default dir\n",
    "os.chdir(\"/Users/pedroteche/Documents/GitHub/maize-crop-diagnose/\")\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir 'data'\n",
    "# !cp -r 'drive/MyDrive/maize-crop-diagnose' 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "print(\"Found GPU at: {}\".format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        iterations,\n",
    "        max_lr=1e-3,\n",
    "        start_lr=None,\n",
    "        start_mom=0.95,\n",
    "        min_mom=0.85,\n",
    "        last_iterations=None,\n",
    "        last_lr=None,\n",
    "    ):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.start_mom = start_mom\n",
    "        self.min_mom = min_mom\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr, self.max_lr)\n",
    "            mom = self._interpolate(\n",
    "                0, self.half_iteration, self.start_mom, self.min_mom\n",
    "            )\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                self.half_iteration, 2 * self.half_iteration, self.max_lr, self.start_lr\n",
    "            )\n",
    "            mom = self._interpolate(\n",
    "                self.half_iteration,\n",
    "                2 * self.half_iteration,\n",
    "                self.min_mom,\n",
    "                self.start_mom,\n",
    "            )\n",
    "        else:\n",
    "            lr = self._interpolate(\n",
    "                2 * self.half_iteration, self.iterations, self.start_lr, self.last_lr\n",
    "            )\n",
    "            mom = self.start_mom\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
    "        K.set_value(self.model.optimizer.momentum, mom)\n",
    "\n",
    "\n",
    "class OneCycleSchedulerNoMom(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        iterations,\n",
    "        max_lr=1e-3,\n",
    "        start_lr=None,\n",
    "        last_iterations=None,\n",
    "        last_lr=None,\n",
    "    ):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr, self.max_lr)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                self.half_iteration, 2 * self.half_iteration, self.max_lr, self.start_lr\n",
    "            )\n",
    "        else:\n",
    "            lr = self._interpolate(\n",
    "                2 * self.half_iteration, self.iterations, self.start_lr, self.last_lr\n",
    "            )\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 64 * 2\n",
    "IMG_WIDTH = 48 * 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 50\n",
    "# DATA_DIR = \"data/maize-crop-diagnose/data/train\"\n",
    "TRAIN_DATA_DIR = \"/Volumes/DOCK-HD/Data/maize-crop-diagnose/train\"\n",
    "TEST_DATA_DIR = \"/Volumes/DOCK-HD/Data/maize-crop-diagnose/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14749 files belonging to 3 classes.\n",
      "Using 11800 files for training.\n",
      "Using 2949 files for validation.\n",
      "369\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "train_set, val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "num_classes = len(train_set.class_names)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "print(train_set.cardinality().numpy())\n",
    "train_set = train_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "val_set = val_set.prefetch(buffer_size=AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 11800\n",
    "TEST_SIZE = 2949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "test_set= tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DATA_DIR,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "test_set = test_set.prefetch(buffer_size=AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple input/output example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "rescale = keras.layers.Rescaling(1.0 / 255)(input)\n",
    "conv_in = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(7, 7), strides=(2, 2), activation=\"relu\"\n",
    ")(rescale)\n",
    "pool_in = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_out = keras.layers.GlobalAveragePooling2D()(pool_in)\n",
    "dense_out = keras.layers.Dense(512, activation=\"relu\")(pool_out)\n",
    "output = keras.layers.Dense(num_classes, activation=\"softmax\")(dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 17s 44ms/step - loss: 1.0185 - accuracy: 0.4600 - val_loss: 0.9392 - val_accuracy: 0.5381\n",
      "Epoch 2/50\n",
      "369/369 [==============================] - 9s 23ms/step - loss: 0.8285 - accuracy: 0.6969 - val_loss: 0.6916 - val_accuracy: 0.7691\n",
      "Epoch 3/50\n",
      "369/369 [==============================] - 9s 23ms/step - loss: 0.6258 - accuracy: 0.7588 - val_loss: 0.6707 - val_accuracy: 0.6999\n",
      "Epoch 4/50\n",
      "369/369 [==============================] - 9s 23ms/step - loss: 0.5399 - accuracy: 0.7853 - val_loss: 0.6014 - val_accuracy: 0.7352\n",
      "Epoch 5/50\n",
      "369/369 [==============================] - 9s 25ms/step - loss: 0.4840 - accuracy: 0.8103 - val_loss: 0.5354 - val_accuracy: 0.7704\n",
      "Epoch 6/50\n",
      "369/369 [==============================] - 10s 28ms/step - loss: 0.4565 - accuracy: 0.8195 - val_loss: 0.5105 - val_accuracy: 0.7870\n",
      "Epoch 7/50\n",
      "369/369 [==============================] - 9s 24ms/step - loss: 0.4308 - accuracy: 0.8285 - val_loss: 0.4420 - val_accuracy: 0.8220\n",
      "Epoch 8/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.4106 - accuracy: 0.8358 - val_loss: 0.4107 - val_accuracy: 0.8318\n",
      "Epoch 9/50\n",
      "369/369 [==============================] - 8s 23ms/step - loss: 0.3961 - accuracy: 0.8399 - val_loss: 0.3951 - val_accuracy: 0.8376\n",
      "Epoch 10/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.3860 - accuracy: 0.8435 - val_loss: 0.4030 - val_accuracy: 0.8345\n",
      "Epoch 11/50\n",
      "369/369 [==============================] - 8s 20ms/step - loss: 0.3785 - accuracy: 0.8473 - val_loss: 0.4037 - val_accuracy: 0.8332\n",
      "Epoch 12/50\n",
      "369/369 [==============================] - 8s 20ms/step - loss: 0.3726 - accuracy: 0.8493 - val_loss: 0.4142 - val_accuracy: 0.8301\n",
      "Epoch 13/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.3685 - accuracy: 0.8510 - val_loss: 0.3779 - val_accuracy: 0.8460\n",
      "Epoch 14/50\n",
      "369/369 [==============================] - 9s 24ms/step - loss: 0.3654 - accuracy: 0.8522 - val_loss: 0.3812 - val_accuracy: 0.8467\n",
      "Epoch 15/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.3616 - accuracy: 0.8539 - val_loss: 0.3732 - val_accuracy: 0.8505\n",
      "Epoch 16/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.3593 - accuracy: 0.8555 - val_loss: 0.3746 - val_accuracy: 0.8498\n",
      "Epoch 17/50\n",
      "369/369 [==============================] - 8s 23ms/step - loss: 0.3550 - accuracy: 0.8561 - val_loss: 0.3728 - val_accuracy: 0.8522\n",
      "Epoch 18/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.3541 - accuracy: 0.8579 - val_loss: 0.3236 - val_accuracy: 0.8671\n",
      "Epoch 19/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.3451 - accuracy: 0.8606 - val_loss: 0.3084 - val_accuracy: 0.8711\n",
      "Epoch 20/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.3470 - accuracy: 0.8588 - val_loss: 0.3176 - val_accuracy: 0.8657\n",
      "Epoch 21/50\n",
      "369/369 [==============================] - 9s 24ms/step - loss: 0.3462 - accuracy: 0.8615 - val_loss: 0.3025 - val_accuracy: 0.8732\n",
      "Epoch 22/50\n",
      "369/369 [==============================] - 8s 23ms/step - loss: 0.3807 - accuracy: 0.8464 - val_loss: 0.7260 - val_accuracy: 0.6751\n",
      "Epoch 23/50\n",
      "369/369 [==============================] - 8s 23ms/step - loss: 0.3554 - accuracy: 0.8596 - val_loss: 0.3000 - val_accuracy: 0.8745\n",
      "Epoch 24/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.3274 - accuracy: 0.8700 - val_loss: 0.2885 - val_accuracy: 0.8820\n",
      "Epoch 25/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.3198 - accuracy: 0.8719 - val_loss: 0.2784 - val_accuracy: 0.8888\n",
      "Epoch 26/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.3090 - accuracy: 0.8778 - val_loss: 0.2704 - val_accuracy: 0.8895\n",
      "Epoch 27/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2963 - accuracy: 0.8825 - val_loss: 0.2605 - val_accuracy: 0.8962\n",
      "Epoch 28/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2899 - accuracy: 0.8844 - val_loss: 0.2533 - val_accuracy: 0.9000\n",
      "Epoch 29/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2840 - accuracy: 0.8869 - val_loss: 0.2485 - val_accuracy: 0.9017\n",
      "Epoch 30/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2775 - accuracy: 0.8903 - val_loss: 0.2438 - val_accuracy: 0.9061\n",
      "Epoch 31/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2709 - accuracy: 0.8939 - val_loss: 0.2384 - val_accuracy: 0.9084\n",
      "Epoch 32/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2648 - accuracy: 0.8967 - val_loss: 0.2333 - val_accuracy: 0.9101\n",
      "Epoch 33/50\n",
      "369/369 [==============================] - 9s 24ms/step - loss: 0.2583 - accuracy: 0.8992 - val_loss: 0.2288 - val_accuracy: 0.9101\n",
      "Epoch 34/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.2530 - accuracy: 0.9018 - val_loss: 0.2248 - val_accuracy: 0.9118\n",
      "Epoch 35/50\n",
      "369/369 [==============================] - 9s 24ms/step - loss: 0.2476 - accuracy: 0.9043 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
      "Epoch 36/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.2414 - accuracy: 0.9078 - val_loss: 0.2169 - val_accuracy: 0.9145\n",
      "Epoch 37/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2347 - accuracy: 0.9105 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 38/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2285 - accuracy: 0.9122 - val_loss: 0.2096 - val_accuracy: 0.9156\n",
      "Epoch 39/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2223 - accuracy: 0.9162 - val_loss: 0.2065 - val_accuracy: 0.9149\n",
      "Epoch 40/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.2164 - accuracy: 0.9193 - val_loss: 0.2031 - val_accuracy: 0.9169\n",
      "Epoch 41/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2105 - accuracy: 0.9214 - val_loss: 0.2000 - val_accuracy: 0.9183\n",
      "Epoch 42/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.2044 - accuracy: 0.9241 - val_loss: 0.1968 - val_accuracy: 0.9190\n",
      "Epoch 43/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.1986 - accuracy: 0.9257 - val_loss: 0.1935 - val_accuracy: 0.9196\n",
      "Epoch 44/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.1931 - accuracy: 0.9278 - val_loss: 0.1901 - val_accuracy: 0.9230\n",
      "Epoch 45/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.1880 - accuracy: 0.9297 - val_loss: 0.1868 - val_accuracy: 0.9244\n",
      "Epoch 46/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.1842 - accuracy: 0.9314 - val_loss: 0.1844 - val_accuracy: 0.9268\n",
      "Epoch 47/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.1816 - accuracy: 0.9321 - val_loss: 0.1822 - val_accuracy: 0.9281\n",
      "Epoch 48/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.1792 - accuracy: 0.9336 - val_loss: 0.1798 - val_accuracy: 0.9298\n",
      "Epoch 49/50\n",
      "369/369 [==============================] - 8s 21ms/step - loss: 0.1770 - accuracy: 0.9342 - val_loss: 0.1771 - val_accuracy: 0.9312\n",
      "Epoch 50/50\n",
      "369/369 [==============================] - 8s 22ms/step - loss: 0.1752 - accuracy: 0.9345 - val_loss: 0.1752 - val_accuracy: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173d52b60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecycle = OneCycleSchedulerNoMom(\n",
    "    TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "    max_lr=0.1,\n",
    "    start_lr=0.01,\n",
    "    last_lr=0.001,\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, onecycle],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Residual Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "input = keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "rescale = keras.layers.Rescaling(1.0 / 255)(input)\n",
    "conv_in = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(7, 7), strides=(2, 2), activation=\"relu\"\n",
    ")(rescale)\n",
    "pool_in = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding = \"same\")(conv_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_r1_1 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(pool_in)\n",
    "bn_r1_1 = keras.layers.BatchNormalization()(conv_r1_1)\n",
    "relu_r1_1 = keras.layers.ReLU()(bn_r1_1)\n",
    "conv_r1_2 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(relu_r1_1)\n",
    "bn_r1_2 = keras.layers.BatchNormalization()(conv_r1_2)\n",
    "skip_r1 = keras.layers.Add()([bn_r1_2, pool_in])\n",
    "relu_r1_2 = keras.layers.ReLU()(skip_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_out = keras.layers.GlobalAveragePooling2D()(relu_r1_2)\n",
    "dense_out = keras.layers.Dense(512, activation=\"relu\")(pool_out)\n",
    "output = keras.layers.Dense(num_classes, activation=\"softmax\")(dense_out)\n",
    "\n",
    "model = keras.Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "369/369 [==============================] - 13s 35ms/step - loss: 0.4590 - accuracy: 0.8373 - val_loss: 0.5213 - val_accuracy: 0.8057\n",
      "Epoch 2/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.3212 - accuracy: 0.8759 - val_loss: 0.3311 - val_accuracy: 0.8688\n",
      "Epoch 3/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.2718 - accuracy: 0.8962 - val_loss: 0.5256 - val_accuracy: 0.8206\n",
      "Epoch 4/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.2576 - accuracy: 0.9008 - val_loss: 0.2376 - val_accuracy: 0.9054\n",
      "Epoch 5/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.2238 - accuracy: 0.9141 - val_loss: 0.3624 - val_accuracy: 0.8633\n",
      "Epoch 6/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.1974 - accuracy: 0.9261 - val_loss: 0.4479 - val_accuracy: 0.8511\n",
      "Epoch 7/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.1790 - accuracy: 0.9344 - val_loss: 0.3635 - val_accuracy: 0.8606\n",
      "Epoch 8/50\n",
      "369/369 [==============================] - 13s 34ms/step - loss: 0.1681 - accuracy: 0.9379 - val_loss: 0.2333 - val_accuracy: 0.9074\n",
      "Epoch 9/50\n",
      "369/369 [==============================] - 13s 35ms/step - loss: 0.1556 - accuracy: 0.9431 - val_loss: 0.2039 - val_accuracy: 0.9264\n",
      "Epoch 10/50\n",
      "369/369 [==============================] - 12s 34ms/step - loss: 0.1487 - accuracy: 0.9467 - val_loss: 0.1868 - val_accuracy: 0.9312\n",
      "Epoch 11/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.1394 - accuracy: 0.9501 - val_loss: 0.1845 - val_accuracy: 0.9400\n",
      "Epoch 12/50\n",
      "369/369 [==============================] - 13s 35ms/step - loss: 0.1309 - accuracy: 0.9538 - val_loss: 0.3662 - val_accuracy: 0.8715\n",
      "Epoch 13/50\n",
      "369/369 [==============================] - 13s 35ms/step - loss: 0.1226 - accuracy: 0.9574 - val_loss: 0.6946 - val_accuracy: 0.7589\n",
      "Epoch 14/50\n",
      "369/369 [==============================] - 12s 34ms/step - loss: 0.1184 - accuracy: 0.9591 - val_loss: 0.7438 - val_accuracy: 0.7128\n",
      "Epoch 15/50\n",
      "369/369 [==============================] - 12s 32ms/step - loss: 0.1141 - accuracy: 0.9601 - val_loss: 0.7352 - val_accuracy: 0.7209\n",
      "Epoch 16/50\n",
      "369/369 [==============================] - 11s 31ms/step - loss: 0.1082 - accuracy: 0.9623 - val_loss: 0.5631 - val_accuracy: 0.7945\n",
      "Epoch 17/50\n",
      "369/369 [==============================] - 12s 32ms/step - loss: 0.1031 - accuracy: 0.9637 - val_loss: 0.6845 - val_accuracy: 0.7436\n",
      "Epoch 18/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.0990 - accuracy: 0.9666 - val_loss: 0.5842 - val_accuracy: 0.7860\n",
      "Epoch 19/50\n",
      "369/369 [==============================] - 12s 34ms/step - loss: 0.0961 - accuracy: 0.9671 - val_loss: 0.6651 - val_accuracy: 0.7487\n",
      "Epoch 20/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.0928 - accuracy: 0.9684 - val_loss: 0.1778 - val_accuracy: 0.9346\n",
      "Epoch 21/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.0897 - accuracy: 0.9704 - val_loss: 0.3259 - val_accuracy: 0.8694\n",
      "Epoch 22/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.0856 - accuracy: 0.9707 - val_loss: 0.1869 - val_accuracy: 0.9271\n",
      "Epoch 23/50\n",
      "369/369 [==============================] - 12s 32ms/step - loss: 0.0808 - accuracy: 0.9731 - val_loss: 0.2934 - val_accuracy: 0.8688\n",
      "Epoch 24/50\n",
      "369/369 [==============================] - 12s 32ms/step - loss: 0.0764 - accuracy: 0.9742 - val_loss: 0.3993 - val_accuracy: 0.8267\n",
      "Epoch 25/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.0710 - accuracy: 0.9758 - val_loss: 0.4614 - val_accuracy: 0.8030\n",
      "Epoch 26/50\n",
      "369/369 [==============================] - 12s 33ms/step - loss: 0.0677 - accuracy: 0.9770 - val_loss: 0.5373 - val_accuracy: 0.7969\n",
      "Epoch 27/50\n",
      "369/369 [==============================] - 13s 34ms/step - loss: 0.0625 - accuracy: 0.9802 - val_loss: 0.4051 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x299341a20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecycle = OneCycleSchedulerNoMom(\n",
    "    TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "    max_lr=0.1,\n",
    "    start_lr=0.01,\n",
    "    last_lr=0.001,\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, start_from_epoch=20)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, onecycle],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Residual Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# Input layers\n",
    "input = keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "rescale = keras.layers.Rescaling(1.0 / 255)(input)\n",
    "conv_in = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(7, 7), strides=(2, 2), activation=\"relu\"\n",
    ")(rescale)\n",
    "pool_in = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding = \"same\")(conv_in)\n",
    "# R1\n",
    "conv_r1_1 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(pool_in)\n",
    "bn_r1_1 = keras.layers.BatchNormalization()(conv_r1_1)\n",
    "relu_r1_1 = keras.layers.ReLU()(bn_r1_1)\n",
    "conv_r1_2 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(relu_r1_1)\n",
    "bn_r1_2 = keras.layers.BatchNormalization()(conv_r1_2)\n",
    "skip_r1 = keras.layers.Add()([bn_r1_2, pool_in])\n",
    "relu_r1_2 = keras.layers.ReLU()(skip_r1)\n",
    "# R2\n",
    "conv_r2_1 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(relu_r1_2)\n",
    "bn_r2_1 = keras.layers.BatchNormalization()(conv_r2_1)\n",
    "relu_r2_1 = keras.layers.ReLU()(bn_r2_1)\n",
    "conv_r2_2 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(relu_r2_1)\n",
    "bn_r2_2 = keras.layers.BatchNormalization()(conv_r2_2)\n",
    "skip_r2 = keras.layers.Add()([bn_r2_2, conv_r2_1])\n",
    "relu_r2_2 = keras.layers.ReLU()(skip_r2)\n",
    "# Output layers\n",
    "pool_out = keras.layers.GlobalAveragePooling2D()(relu_r2_2)\n",
    "dense_out = keras.layers.Dense(512, activation=\"relu\")(pool_out)\n",
    "output = keras.layers.Dense(num_classes, activation=\"softmax\")(dense_out)\n",
    "# Model\n",
    "model = keras.Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "369/369 [==============================] - 22s 57ms/step - loss: 0.4148 - accuracy: 0.8431 - val_loss: 0.5897 - val_accuracy: 0.7596\n",
      "Epoch 2/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.3193 - accuracy: 0.8777 - val_loss: 0.3175 - val_accuracy: 0.8772\n",
      "Epoch 3/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.2698 - accuracy: 0.8962 - val_loss: 0.4354 - val_accuracy: 0.8532\n",
      "Epoch 4/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.2257 - accuracy: 0.9154 - val_loss: 0.2962 - val_accuracy: 0.8922\n",
      "Epoch 5/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1965 - accuracy: 0.9277 - val_loss: 0.2653 - val_accuracy: 0.9047\n",
      "Epoch 6/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.1754 - accuracy: 0.9368 - val_loss: 0.1877 - val_accuracy: 0.9376\n",
      "Epoch 7/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1583 - accuracy: 0.9438 - val_loss: 0.1370 - val_accuracy: 0.9566\n",
      "Epoch 8/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1455 - accuracy: 0.9494 - val_loss: 0.1352 - val_accuracy: 0.9508\n",
      "Epoch 9/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.1379 - accuracy: 0.9510 - val_loss: 0.1221 - val_accuracy: 0.9535\n",
      "Epoch 10/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.1255 - accuracy: 0.9546 - val_loss: 0.1193 - val_accuracy: 0.9535\n",
      "Epoch 11/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1217 - accuracy: 0.9571 - val_loss: 0.1227 - val_accuracy: 0.9522\n",
      "Epoch 12/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1111 - accuracy: 0.9606 - val_loss: 0.1332 - val_accuracy: 0.9505\n",
      "Epoch 13/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1044 - accuracy: 0.9625 - val_loss: 0.1013 - val_accuracy: 0.9617\n",
      "Epoch 14/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0972 - accuracy: 0.9652 - val_loss: 0.1080 - val_accuracy: 0.9603\n",
      "Epoch 15/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0937 - accuracy: 0.9673 - val_loss: 0.1203 - val_accuracy: 0.9556\n",
      "Epoch 16/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0893 - accuracy: 0.9686 - val_loss: 0.1302 - val_accuracy: 0.9481\n",
      "Epoch 17/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0852 - accuracy: 0.9686 - val_loss: 0.2010 - val_accuracy: 0.9203\n",
      "Epoch 18/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0912 - accuracy: 0.9681 - val_loss: 0.2423 - val_accuracy: 0.9159\n",
      "Epoch 19/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0786 - accuracy: 0.9715 - val_loss: 0.1558 - val_accuracy: 0.9440\n",
      "Epoch 20/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0753 - accuracy: 0.9721 - val_loss: 0.3713 - val_accuracy: 0.8864\n",
      "Epoch 21/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0706 - accuracy: 0.9747 - val_loss: 0.4341 - val_accuracy: 0.8756\n",
      "Epoch 22/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0690 - accuracy: 0.9758 - val_loss: 0.1789 - val_accuracy: 0.9407\n",
      "Epoch 23/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0661 - accuracy: 0.9770 - val_loss: 0.1530 - val_accuracy: 0.9491\n",
      "Epoch 24/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0617 - accuracy: 0.9787 - val_loss: 0.2959 - val_accuracy: 0.9247\n",
      "Epoch 25/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0577 - accuracy: 0.9799 - val_loss: 0.4437 - val_accuracy: 0.9010\n",
      "Epoch 26/50\n",
      "369/369 [==============================] - 16s 42ms/step - loss: 0.0507 - accuracy: 0.9834 - val_loss: 0.3671 - val_accuracy: 0.9118\n",
      "Epoch 27/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 0.2665 - val_accuracy: 0.9318\n",
      "Epoch 28/50\n",
      "369/369 [==============================] - 16s 45ms/step - loss: 0.0465 - accuracy: 0.9845 - val_loss: 0.2852 - val_accuracy: 0.9335\n",
      "Epoch 29/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0388 - accuracy: 0.9885 - val_loss: 0.2678 - val_accuracy: 0.9390\n",
      "Epoch 30/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.1575 - val_accuracy: 0.9596\n",
      "Epoch 31/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.1264 - val_accuracy: 0.9685\n",
      "Epoch 32/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.1172 - val_accuracy: 0.9681\n",
      "Epoch 33/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.0961 - val_accuracy: 0.9732\n",
      "Epoch 34/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.0797 - val_accuracy: 0.9766\n",
      "Epoch 35/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0758 - val_accuracy: 0.9776\n",
      "Epoch 36/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.2153 - val_accuracy: 0.9464\n",
      "Epoch 37/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.0653 - val_accuracy: 0.9820\n",
      "Epoch 38/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.0802 - val_accuracy: 0.9759\n",
      "Epoch 39/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0828 - val_accuracy: 0.9790\n",
      "Epoch 40/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 0.0749 - val_accuracy: 0.9797\n",
      "Epoch 41/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 0.0782 - val_accuracy: 0.9800\n",
      "Epoch 42/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0108 - accuracy: 0.9981 - val_loss: 0.0781 - val_accuracy: 0.9803\n",
      "Epoch 43/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0807 - val_accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.0810 - val_accuracy: 0.9793\n",
      "Epoch 45/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.0773 - val_accuracy: 0.9797\n",
      "Epoch 46/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0741 - val_accuracy: 0.9810\n",
      "Epoch 47/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.0720 - val_accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c8393670>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecycle = OneCycleSchedulerNoMom(\n",
    "    TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "    max_lr=0.1,\n",
    "    start_lr=0.01,\n",
    "    last_lr=0.001,\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, start_from_epoch=20)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, onecycle],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Residual Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# Input layers\n",
    "input = keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "rescale = keras.layers.Rescaling(1.0 / 255)(input)\n",
    "conv_in = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(7, 7), strides=(2, 2), activation=\"relu\"\n",
    ")(rescale)\n",
    "pool_in = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding = \"same\")(conv_in)\n",
    "# R1\n",
    "conv_r1_1 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(pool_in)\n",
    "bn_r1_1 = keras.layers.BatchNormalization()(conv_r1_1)\n",
    "relu_r1_1 = keras.layers.ReLU()(bn_r1_1)\n",
    "conv_r1_2 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(relu_r1_1)\n",
    "bn_r1_2 = keras.layers.BatchNormalization()(conv_r1_2)\n",
    "skip_r1 = keras.layers.Add()([bn_r1_2, pool_in])\n",
    "relu_r1_2 = keras.layers.ReLU()(skip_r1)\n",
    "# R2\n",
    "conv_r2_1 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(relu_r1_2)\n",
    "bn_r2_1 = keras.layers.BatchNormalization()(conv_r2_1)\n",
    "relu_r2_1 = keras.layers.ReLU()(bn_r2_1)\n",
    "conv_r2_2 = keras.layers.Conv2D(64, 3, 1, padding = \"same\")(relu_r2_1)\n",
    "bn_r2_2 = keras.layers.BatchNormalization()(conv_r2_2)\n",
    "skip_r2 = keras.layers.Add()([bn_r2_2, relu_r1_2])\n",
    "relu_r2_2 = keras.layers.ReLU()(skip_r2)\n",
    "# R3\n",
    "conv_r3_skip = keras.layers.Conv2D(128, 1, 2, padding = \"same\")(relu_r2_2)\n",
    "conv_r3_1 = keras.layers.Conv2D(128, 3, 2, padding = \"same\")(relu_r2_2)\n",
    "bn_r3_1 = keras.layers.BatchNormalization()(conv_r3_1)\n",
    "relu_r3_1 = keras.layers.ReLU()(bn_r3_1)\n",
    "conv_r3_2 = keras.layers.Conv2D(128, 3, 1, padding = \"same\")(relu_r3_1)\n",
    "bn_r3_2 = keras.layers.BatchNormalization()(conv_r3_2)\n",
    "skip_r3 = keras.layers.Add()([bn_r3_2, conv_r3_skip])\n",
    "relu_r3_2 = keras.layers.ReLU()(skip_r2)\n",
    "# Output layers\n",
    "pool_out = keras.layers.GlobalAveragePooling2D()(relu_r2_2)\n",
    "dense_out = keras.layers.Dense(512, activation=\"relu\")(pool_out)\n",
    "output = keras.layers.Dense(num_classes, activation=\"softmax\")(dense_out)\n",
    "# Model\n",
    "model = keras.Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "369/369 [==============================] - 23s 61ms/step - loss: 0.4100 - accuracy: 0.8442 - val_loss: 0.4650 - val_accuracy: 0.8345\n",
      "Epoch 2/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.2800 - accuracy: 0.8940 - val_loss: 0.3555 - val_accuracy: 0.8674\n",
      "Epoch 3/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.2289 - accuracy: 0.9140 - val_loss: 0.8192 - val_accuracy: 0.6924\n",
      "Epoch 4/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.2370 - accuracy: 0.9117 - val_loss: 0.8163 - val_accuracy: 0.7362\n",
      "Epoch 5/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.2049 - accuracy: 0.9240 - val_loss: 0.6976 - val_accuracy: 0.8047\n",
      "Epoch 6/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1698 - accuracy: 0.9381 - val_loss: 0.8491 - val_accuracy: 0.7586\n",
      "Epoch 7/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1535 - accuracy: 0.9445 - val_loss: 1.2112 - val_accuracy: 0.6850\n",
      "Epoch 8/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.1407 - accuracy: 0.9495 - val_loss: 1.2253 - val_accuracy: 0.6575\n",
      "Epoch 9/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1231 - accuracy: 0.9561 - val_loss: 4.7298 - val_accuracy: 0.5056\n",
      "Epoch 10/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.1396 - accuracy: 0.9486 - val_loss: 0.4918 - val_accuracy: 0.8549\n",
      "Epoch 11/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1048 - accuracy: 0.9627 - val_loss: 1.5814 - val_accuracy: 0.6575\n",
      "Epoch 12/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0972 - accuracy: 0.9665 - val_loss: 1.4227 - val_accuracy: 0.6663\n",
      "Epoch 13/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.1060 - accuracy: 0.9649 - val_loss: 0.2778 - val_accuracy: 0.9013\n",
      "Epoch 14/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0857 - accuracy: 0.9719 - val_loss: 0.3065 - val_accuracy: 0.8966\n",
      "Epoch 15/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0926 - accuracy: 0.9697 - val_loss: 0.1526 - val_accuracy: 0.9505\n",
      "Epoch 16/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 0.1273 - val_accuracy: 0.9603\n",
      "Epoch 17/50\n",
      "369/369 [==============================] - 17s 46ms/step - loss: 0.0792 - accuracy: 0.9735 - val_loss: 0.1392 - val_accuracy: 0.9559\n",
      "Epoch 18/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0770 - accuracy: 0.9749 - val_loss: 0.1258 - val_accuracy: 0.9610\n",
      "Epoch 19/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0725 - accuracy: 0.9764 - val_loss: 0.2835 - val_accuracy: 0.8810\n",
      "Epoch 20/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0689 - accuracy: 0.9781 - val_loss: 0.1944 - val_accuracy: 0.9230\n",
      "Epoch 21/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0666 - accuracy: 0.9783 - val_loss: 0.4740 - val_accuracy: 0.8386\n",
      "Epoch 22/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0631 - accuracy: 0.9802 - val_loss: 0.6600 - val_accuracy: 0.7976\n",
      "Epoch 23/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0593 - accuracy: 0.9813 - val_loss: 0.0995 - val_accuracy: 0.9630\n",
      "Epoch 24/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.1161 - val_accuracy: 0.9603\n",
      "Epoch 25/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.0964 - val_accuracy: 0.9691\n",
      "Epoch 26/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 0.1205 - val_accuracy: 0.9603\n",
      "Epoch 27/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 0.1011 - val_accuracy: 0.9658\n",
      "Epoch 28/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.0940 - val_accuracy: 0.9698\n",
      "Epoch 29/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.1000 - val_accuracy: 0.9681\n",
      "Epoch 30/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.0902 - val_accuracy: 0.9719\n",
      "Epoch 31/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0872 - val_accuracy: 0.9732\n",
      "Epoch 32/50\n",
      "369/369 [==============================] - 18s 48ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0864 - val_accuracy: 0.9736\n",
      "Epoch 33/50\n",
      "369/369 [==============================] - 17s 45ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.1010 - val_accuracy: 0.9685\n",
      "Epoch 34/50\n",
      "369/369 [==============================] - 17s 45ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.1460 - val_accuracy: 0.9552\n",
      "Epoch 35/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0926 - val_accuracy: 0.9742\n",
      "Epoch 36/50\n",
      "369/369 [==============================] - 17s 45ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0993 - val_accuracy: 0.9742\n",
      "Epoch 37/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.1042 - val_accuracy: 0.9746\n",
      "Epoch 38/50\n",
      "369/369 [==============================] - 17s 45ms/step - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.0963 - val_accuracy: 0.9769\n",
      "Epoch 39/50\n",
      "369/369 [==============================] - 17s 45ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0924 - val_accuracy: 0.9769\n",
      "Epoch 40/50\n",
      "369/369 [==============================] - 17s 45ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.0859 - val_accuracy: 0.9769\n",
      "Epoch 41/50\n",
      "369/369 [==============================] - 16s 45ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0833 - val_accuracy: 0.9773\n",
      "Epoch 42/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0837 - val_accuracy: 0.9780\n",
      "Epoch 43/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0856 - val_accuracy: 0.9763\n",
      "Epoch 44/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0838 - val_accuracy: 0.9776\n",
      "Epoch 45/50\n",
      "369/369 [==============================] - 15s 42ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0821 - val_accuracy: 0.9803\n",
      "Epoch 46/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0811 - val_accuracy: 0.9810\n",
      "Epoch 47/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0804 - val_accuracy: 0.9817\n",
      "Epoch 48/50\n",
      "369/369 [==============================] - 17s 45ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0800 - val_accuracy: 0.9820\n",
      "Epoch 49/50\n",
      "369/369 [==============================] - 16s 44ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0798 - val_accuracy: 0.9824\n",
      "Epoch 50/50\n",
      "369/369 [==============================] - 16s 43ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0796 - val_accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x34b008100>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecycle = OneCycleSchedulerNoMom(\n",
    "    TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "    max_lr=0.1,\n",
    "    start_lr=0.01,\n",
    "    last_lr=0.001,\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, start_from_epoch=20)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, onecycle],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    K.clear_session()\n",
    "    train_set, val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "        DATA_DIR,\n",
    "        validation_split=0.2,\n",
    "        subset=\"both\",\n",
    "        seed=42,\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    num_classes = len(train_set.class_names)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_set = train_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "    val_set = val_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "\n",
    "    # Network architecture\n",
    "    ## Input\n",
    "    ### Hyperparameters for input\n",
    "    input_kernel_size = trial.suggest_categorical(\"input_kernel_size\", [3, 5, 7])\n",
    "    ### Architecture\n",
    "    input_layer = keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    conv_layer_1 = keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=input_kernel_size, activation=\"relu\"\n",
    "    )(input_layer)\n",
    "    pool_layer_1 = keras.layers.MaxPooling2D()(conv_layer_1)\n",
    "    ## Residual Layers\n",
    "    ### Hyperparameters for Residual\n",
    "    residual_kernel_size = trial.suggest_categorical(\"residual_kernel_size\", [3, 5, 7])\n",
    "    ### Architecture\n",
    "    #### R1\n",
    "    r1_conv_layer1 = keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=residual_kernel_size,\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "    )(pool_layer_1)\n",
    "    r1_batch_norm = keras.layers.BatchNormalization()(r1_conv_layer1)\n",
    "    r1_conv_layer2 = keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=residual_kernel_size, padding=\"same\"\n",
    "    )(r1_batch_norm)\n",
    "    r1_batch_norm_2 = keras.layers.BatchNormalization()(r1_conv_layer2)\n",
    "    r1_out = keras.layers.Add()([pool_layer_1, r1_batch_norm_2])\n",
    "    r1_relu = keras.layers.ReLU()(r1_out)\n",
    "    #### R2\n",
    "    r2_conv_layer1 = keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=residual_kernel_size,\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "    )(r1_relu)\n",
    "    r2_batch_norm = keras.layers.BatchNormalization()(r2_conv_layer1)\n",
    "    r2_conv_layer2 = keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=residual_kernel_size, padding=\"same\"\n",
    "    )(r2_batch_norm)\n",
    "    r2_batch_norm_2 = keras.layers.BatchNormalization()(r2_conv_layer2)\n",
    "    r2_out = keras.layers.Add()([r1_relu, r2_batch_norm_2])\n",
    "    r2_relu = keras.layers.ReLU()(r2_out)\n",
    "    #### R3\n",
    "    r3_conv_layer1 = keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        strides=2,\n",
    "        kernel_size=residual_kernel_size,\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "    )(r2_relu)\n",
    "    r3_batch_norm = keras.layers.BatchNormalization()(r3_conv_layer1)\n",
    "    r3_conv_layer2 = keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=residual_kernel_size, padding=\"same\"\n",
    "    )(r3_batch_norm)\n",
    "    r3_batch_norm_2 = keras.layers.BatchNormalization()(r3_conv_layer2)\n",
    "    r3_conv_layer_inter = keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        strides=2,\n",
    "        kernel_size=1,\n",
    "        padding=\"same\",\n",
    "    )(r2_relu)\n",
    "    r3_out = keras.layers.Add()([r3_conv_layer_inter, r3_batch_norm_2])\n",
    "    r3_relu = keras.layers.ReLU()(r3_out)\n",
    "\n",
    "    ## Output\n",
    "    ### Hyperparameters for Output\n",
    "    num_output = trial.suggest_int(\"num_input_filter\", 16, 128)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    ### Architecture\n",
    "    pool = keras.layers.MaxPooling2D()(r3_relu)\n",
    "    flatten = keras.layers.Flatten()(pool)\n",
    "    dense = keras.layers.Dense(num_output, activation=\"relu\")(flatten)\n",
    "    dropout = keras.layers.Dropout(dropout_rate)(dense)\n",
    "    output = keras.layers.Dense(num_classes, activation=\"softmax\")(dropout)\n",
    "    # Model definition\n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    # Hyperparameters for OneCycleScheduler\n",
    "    max_lr = trial.suggest_float(\"max_lr\", 0.005, 0.5)\n",
    "    start_lr = trial.suggest_float(\"start_lr\", max_lr * 0.01, max_lr * 0.8)\n",
    "    last_lr = trial.suggest_float(\"last_lr\", start_lr, max_lr)\n",
    "    # Model definition\n",
    "    onecycle = OneCycleSchedulerNoMom(\n",
    "        TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "        max_lr=max_lr,\n",
    "        start_lr=start_lr,\n",
    "        last_lr=last_lr,\n",
    "    )\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    # Fitting model\n",
    "    history = model.fit(\n",
    "        train_set,\n",
    "        validation_data=val_set,\n",
    "        epochs=EPOCH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stopping, onecycle],\n",
    "    )\n",
    "    # Evaluating and returning F1 score\n",
    "    loss, acc = model.evaluate(val_set)\n",
    "    return acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    storage=\"sqlite:///drive/MyDrive/maize-crop-diagnose/db_maize_models.sqlite3\",\n",
    "    study_name=\"resnet_onecycle_sgd\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(f\"Best value: {study.best_value} (params: {study.best_params})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
