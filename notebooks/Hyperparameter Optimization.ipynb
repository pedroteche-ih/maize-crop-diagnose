{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os, optuna\n",
    "import warnings\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "K = keras.backend\n",
    "# Changing default dir\n",
    "os.chdir(\"/Users/pedroteche/Documents/GitHub/maize-crop-diagnose/\")\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        iterations,\n",
    "        max_lr=1e-3,\n",
    "        start_lr=None,\n",
    "        start_mom=0.95,\n",
    "        min_mom=0.85,\n",
    "        last_iterations=None,\n",
    "        last_lr=None,\n",
    "    ):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.start_mom = start_mom\n",
    "        self.min_mom = min_mom\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr, self.max_lr)\n",
    "            mom = self._interpolate(\n",
    "                0, self.half_iteration, self.start_mom, self.min_mom\n",
    "            )\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                self.half_iteration, 2 * self.half_iteration, self.max_lr, self.start_lr\n",
    "            )\n",
    "            mom = self._interpolate(\n",
    "                self.half_iteration,\n",
    "                2 * self.half_iteration,\n",
    "                self.min_mom,\n",
    "                self.start_mom,\n",
    "            )\n",
    "        else:\n",
    "            lr = self._interpolate(\n",
    "                2 * self.half_iteration, self.iterations, self.start_lr, self.last_lr\n",
    "            )\n",
    "            mom = self.start_mom\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
    "        K.set_value(self.model.optimizer.momentum, mom)\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 64 * 2\n",
    "IMG_WIDTH = 48 * 2\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SIZE = 10000\n",
    "TEST_SIZE = 3000\n",
    "EPOCH = 50\n",
    "DATA_DIR = \"data/raw/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_data = tf.keras.utils.image_dataset_from_directory(\n",
    "#         DATA_DIR,\n",
    "#         image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#     )\n",
    "# num_classes = len(img_data.class_names)\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# train_set = img_data.take(TRAIN_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "# test_set = img_data.skip(TRAIN_SIZE).take(TEST_SIZE)\n",
    "# val_set = img_data.skip(TRAIN_SIZE).skip(TEST_SIZE).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-07 12:09:30,966]\u001b[0m Using an existing study with name 'cnn_onecycle_sgd' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14749 files belonging to 3 classes.\n",
      "Using 11800 files for training.\n",
      "Using 2949 files for validation.\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 12:09:32.156416: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 173s 466ms/step - loss: 0.4431 - accuracy: 0.8269 - val_loss: 1.1993 - val_accuracy: 0.5320\n",
      "Epoch 2/50\n",
      "369/369 [==============================] - 190s 514ms/step - loss: 0.3000 - accuracy: 0.8833 - val_loss: 1.0032 - val_accuracy: 0.6287\n",
      "Epoch 3/50\n",
      "369/369 [==============================] - 176s 477ms/step - loss: 0.2344 - accuracy: 0.9117 - val_loss: 1.4210 - val_accuracy: 0.5164\n",
      "Epoch 4/50\n",
      "369/369 [==============================] - 167s 452ms/step - loss: 0.1598 - accuracy: 0.9454 - val_loss: 1.3945 - val_accuracy: 0.5480\n",
      "Epoch 5/50\n",
      "369/369 [==============================] - 179s 486ms/step - loss: 0.0959 - accuracy: 0.9699 - val_loss: 1.4517 - val_accuracy: 0.5568\n",
      "Epoch 6/50\n",
      "369/369 [==============================] - 184s 498ms/step - loss: 0.0803 - accuracy: 0.9736 - val_loss: 1.1640 - val_accuracy: 0.6673\n",
      "Epoch 7/50\n",
      "369/369 [==============================] - 174s 470ms/step - loss: 0.0762 - accuracy: 0.9743 - val_loss: 1.2241 - val_accuracy: 0.6480\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 1.0032 - accuracy: 0.6287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-07 12:30:22,209]\u001b[0m Trial 6 finished with value: 0.6286876797676086 and parameters: {'filters_layer_1': 64, 'prop_filters_layer_2': 3, 'prop_filters_layer_3': 2, 'kernel_layer_1': 5, 'kernel_layer_2': 5, 'kernel_layer_3': 3, 'activation': 'elu', 'dropout_rate': 0.33605408567000167, 'dense_size': 128, 'max_lr': 0.07577012971359155, 'start_mom': 0.9527052059309298, 'min_mom': 0.871676127776009}. Best is trial 6 with value: 0.6286876797676086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14749 files belonging to 3 classes.\n",
      "Using 11800 files for training.\n",
      "Using 2949 files for validation.\n",
      "Epoch 1/50\n",
      "369/369 [==============================] - 193s 520ms/step - loss: 0.5502 - accuracy: 0.7914 - val_loss: 1.0868 - val_accuracy: 0.6066\n",
      "Epoch 2/50\n",
      "369/369 [==============================] - 202s 546ms/step - loss: 0.3202 - accuracy: 0.8765 - val_loss: 0.8354 - val_accuracy: 0.6938\n",
      "Epoch 3/50\n",
      "  7/369 [..............................] - ETA: 3:11 - loss: 0.3609 - accuracy: 0.8884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-06-07 12:37:02,857]\u001b[0m Trial 7 failed with parameters: {'filters_layer_1': 64, 'prop_filters_layer_2': 3, 'prop_filters_layer_3': 1, 'kernel_layer_1': 7, 'kernel_layer_2': 5, 'kernel_layer_3': 7, 'activation': 'elu', 'dropout_rate': 0.47857010194870514, 'dense_size': 512, 'max_lr': 0.028138599257157778, 'start_mom': 0.9781135393704212, 'min_mom': 0.8831534532846705} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/c2/4vv1dtt97gl9bn1lvw8rf0k40000gn/T/ipykernel_18411/2263739398.py\", line 93, in objective\n",
      "    history = model.fit(\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 894, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 926, in _call\n",
      "    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 143, in __call__\n",
      "    return concrete_function._call_flat(\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1757, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 381, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"/Users/pedroteche/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-06-07 12:37:02,867]\u001b[0m Trial 7 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 112\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m acc\n\u001b[1;32m    105\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[1;32m    106\u001b[0m     storage\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msqlite:///models/db_optuna.sqlite3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m     study_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcnn_onecycle_sgd\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m     load_if_exists\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m    113\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest value: \u001b[39m\u001b[39m{\u001b[39;00mstudy\u001b[39m.\u001b[39mbest_value\u001b[39m}\u001b[39;00m\u001b[39m (params: \u001b[39m\u001b[39m{\u001b[39;00mstudy\u001b[39m.\u001b[39mbest_params\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[6], line 93\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     87\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     88\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mlegacy\u001b[39m.\u001b[39mSGD(),\n\u001b[1;32m     89\u001b[0m     loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(),\n\u001b[1;32m     90\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[39m# Fitting model\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     94\u001b[0m     train_set,\n\u001b[1;32m     95\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_set,\n\u001b[1;32m     96\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCH,\n\u001b[1;32m     97\u001b[0m     batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m     98\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping, onecycle],\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Evaluating and returning F1 score\u001b[39;00m\n\u001b[1;32m    101\u001b[0m loss, acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(val_set)\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/optuna/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    K.clear_session()\n",
    "    train_set, val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "        DATA_DIR,\n",
    "        validation_split=0.2,\n",
    "        subset=\"both\",\n",
    "        seed=42,\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    num_classes = len(train_set.class_names)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_set = train_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "    val_set = val_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "    # Hyperparameters for network architecture\n",
    "    ## Number of filters\n",
    "    filters_layer_1 = trial.suggest_categorical(\"filters_layer_1\", [16, 32, 64])\n",
    "    filters_layer_2 = trial.suggest_int(\"prop_filters_layer_2\", 1, 4)\n",
    "    filters_layer_3 = trial.suggest_int(\"prop_filters_layer_3\", 1, 4)\n",
    "    ## Kernel size\n",
    "    kernel_layer_1 = trial.suggest_categorical(\"kernel_layer_1\", [3, 5, 7])\n",
    "    kernel_layer_2 = trial.suggest_categorical(\"kernel_layer_2\", [3, 5, 7])\n",
    "    kernel_layer_3 = trial.suggest_categorical(\"kernel_layer_3\", [3, 5, 7])\n",
    "    ## Activation function\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"elu\", \"selu\"])\n",
    "    if activation == \"selu\":\n",
    "        kernel_initializer = \"lecun_normal\"\n",
    "    else:\n",
    "        kernel_initializer = \"he_normal\"\n",
    "    ## Dropout rate\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.25, 0.5)\n",
    "    ## Dense layer size\n",
    "    dense_size = trial.suggest_categorical(\"dense_size\", [16, 32, 64, 128, 256, 512])\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Rescaling(1.0 / 255),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters_layer_1,\n",
    "                kernel_layer_1,\n",
    "                activation=activation,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.SpatialDropout2D(dropout_rate),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters_layer_1 * filters_layer_2,\n",
    "                kernel_layer_2,\n",
    "                activation=activation,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.SpatialDropout2D(dropout_rate),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters_layer_1 * filters_layer_2 * filters_layer_3,\n",
    "                kernel_layer_3,\n",
    "                activation=activation,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.SpatialDropout2D(dropout_rate),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(\n",
    "                dense_size, activation=activation, kernel_initializer=kernel_initializer\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    # Hyperparameters for OneCycleScheduler\n",
    "    max_lr = trial.suggest_float(\"max_lr\", 1e-3, 1e-1)\n",
    "    start_mom = trial.suggest_float(\"start_mom\", 0.9, 0.99)\n",
    "    min_mom_prop = trial.suggest_float(\"min_mom\", 0.8, 0.9)\n",
    "    min_mom = start_mom * min_mom_prop\n",
    "\n",
    "    # Model definition\n",
    "    onecycle = OneCycleScheduler(\n",
    "        TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "        max_lr=max_lr,\n",
    "        start_mom=start_mom,\n",
    "        min_mom=min_mom,\n",
    "    )\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    # Fitting model\n",
    "    history = model.fit(\n",
    "        train_set,\n",
    "        validation_data=val_set,\n",
    "        epochs=EPOCH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stopping, onecycle],\n",
    "    )\n",
    "    # Evaluating and returning F1 score\n",
    "    loss, acc = model.evaluate(val_set)\n",
    "    return acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    storage=\"sqlite:///models/db_optuna.sqlite3\",\n",
    "    study_name=\"cnn_onecycle_sgd\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(f\"Best value: {study.best_value} (params: {study.best_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
