{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os, optuna, warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"local_paths.env\")\n",
    "os.chdir(os.getenv(\"LOCAL_REPO_DIR\"))\n",
    "\n",
    "K = keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        iterations,\n",
    "        max_lr=1e-3,\n",
    "        start_lr=None,\n",
    "        start_mom=0.95,\n",
    "        min_mom=0.85,\n",
    "        last_iterations=None,\n",
    "        last_lr=None,\n",
    "    ):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.start_mom = start_mom\n",
    "        self.min_mom = min_mom\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr, self.max_lr)\n",
    "            mom = self._interpolate(\n",
    "                0, self.half_iteration, self.start_mom, self.min_mom\n",
    "            )\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                self.half_iteration, 2 * self.half_iteration, self.max_lr, self.start_lr\n",
    "            )\n",
    "            mom = self._interpolate(\n",
    "                self.half_iteration,\n",
    "                2 * self.half_iteration,\n",
    "                self.min_mom,\n",
    "                self.start_mom,\n",
    "            )\n",
    "        else:\n",
    "            lr = self._interpolate(\n",
    "                2 * self.half_iteration, self.iterations, self.start_lr, self.last_lr\n",
    "            )\n",
    "            mom = self.start_mom\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
    "        K.set_value(self.model.optimizer.momentum, mom)\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 64 * 2\n",
    "IMG_WIDTH = 48 * 2\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SIZE = 10000\n",
    "TEST_SIZE = 3000\n",
    "EPOCH = 50\n",
    "DATA_DIR = os.getenv(\"LOCAL_DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_data = tf.keras.utils.image_dataset_from_directory(\n",
    "#         DATA_DIR,\n",
    "#         image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#     )\n",
    "# num_classes = len(img_data.class_names)\n",
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# train_set = img_data.take(TRAIN_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "# test_set = img_data.skip(TRAIN_SIZE).take(TEST_SIZE)\n",
    "# val_set = img_data.skip(TRAIN_SIZE).skip(TEST_SIZE).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    K.clear_session()\n",
    "    train_set, val_set = tf.keras.utils.image_dataset_from_directory(\n",
    "        DATA_DIR,\n",
    "        validation_split=0.2,\n",
    "        subset=\"both\",\n",
    "        seed=42,\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    num_classes = len(train_set.class_names)\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_set = train_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "    val_set = val_set.prefetch(buffer_size=AUTOTUNE).cache()\n",
    "    # Hyperparameters for network architecture\n",
    "    ## Number of filters\n",
    "    filters_layer_1 = trial.suggest_categorical(\"filters_layer_1\", [16, 32, 64])\n",
    "    filters_layer_2 = trial.suggest_int(\"prop_filters_layer_2\", 1, 4)\n",
    "    filters_layer_3 = trial.suggest_int(\"prop_filters_layer_3\", 1, 4)\n",
    "    ## Kernel size\n",
    "    kernel_layer_1 = trial.suggest_categorical(\"kernel_layer_1\", [3, 5, 7])\n",
    "    kernel_layer_2 = trial.suggest_categorical(\"kernel_layer_2\", [3, 5, 7])\n",
    "    kernel_layer_3 = trial.suggest_categorical(\"kernel_layer_3\", [3, 5, 7])\n",
    "    ## Activation function\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"elu\", \"selu\"])\n",
    "    if activation == \"selu\":\n",
    "        kernel_initializer = \"lecun_normal\"\n",
    "    else:\n",
    "        kernel_initializer = \"he_normal\"\n",
    "    ## Dropout rate\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.25, 0.5)\n",
    "    ## Dense layer size\n",
    "    dense_size = trial.suggest_categorical(\"dense_size\", [16, 32, 64, 128, 256, 512])\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Rescaling(1.0 / 255),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters_layer_1,\n",
    "                kernel_layer_1,\n",
    "                activation=activation,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.SpatialDropout2D(dropout_rate),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters_layer_1 * filters_layer_2,\n",
    "                kernel_layer_2,\n",
    "                activation=activation,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.SpatialDropout2D(dropout_rate),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters_layer_1 * filters_layer_2 * filters_layer_3,\n",
    "                kernel_layer_3,\n",
    "                activation=activation,\n",
    "                kernel_initializer=kernel_initializer,\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.SpatialDropout2D(dropout_rate),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(\n",
    "                dense_size, activation=activation, kernel_initializer=kernel_initializer\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    # Hyperparameters for OneCycleScheduler\n",
    "    max_lr = trial.suggest_float(\"max_lr\", 1e-3, 1e-1)\n",
    "    start_mom = trial.suggest_float(\"start_mom\", 0.9, 0.99)\n",
    "    min_mom_prop = trial.suggest_float(\"min_mom\", 0.8, 0.9)\n",
    "    min_mom = start_mom * min_mom_prop\n",
    "\n",
    "    # Model definition\n",
    "    onecycle = OneCycleScheduler(\n",
    "        TRAIN_SIZE // BATCH_SIZE * EPOCH,\n",
    "        max_lr=max_lr,\n",
    "        start_mom=start_mom,\n",
    "        min_mom=min_mom,\n",
    "    )\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.SGD(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    # Fitting model\n",
    "    history = model.fit(\n",
    "        train_set,\n",
    "        validation_data=val_set,\n",
    "        epochs=EPOCH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stopping, onecycle],\n",
    "    )\n",
    "    # Evaluating and returning F1 score\n",
    "    loss, acc = model.evaluate(val_set)\n",
    "    return acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    storage=\"sqlite:///models/db_optuna.sqlite3\",\n",
    "    study_name=\"cnn_onecycle_sgd\",\n",
    "    direction=\"maximize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(f\"Best value: {study.best_value} (params: {study.best_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
